<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="How bias and variance relate to underfitting/overfitting"><title>Generalization Error and the Bias-Variance Tradeoff</title>
<link rel=canonical href=https://embergen.github.io/p/generalization-error-and-the-bias-variance-tradeoff/><link rel=stylesheet href=/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="Generalization Error and the Bias-Variance Tradeoff"><meta property='og:description' content="How bias and variance relate to underfitting/overfitting"><meta property='og:url' content='https://embergen.github.io/p/generalization-error-and-the-bias-variance-tradeoff/'><meta property='og:site_name' content="Esther's Learning Journal"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='scikit-learn'><meta property='article:tag' content='supervised learning'><meta property='article:tag' content='python'><meta property='article:tag' content='decision trees'><meta property='article:published_time' content='2025-02-14T00:00:00+00:00'><meta property='article:modified_time' content='2025-02-14T00:00:00+00:00'><meta name=twitter:title content="Generalization Error and the Bias-Variance Tradeoff"><meta name=twitter:description content="How bias and variance relate to underfitting/overfitting"><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/profile_hu_aa20477045f4be10.jpg width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>üç•</span></figure><div class=site-meta><h1 class=site-name><a href=/>Esther's Learning Journal</a></h1><h2 class=site-description>Welcome to my data science journal! I made this site to track my notes as I practice DS concepts. Check out the 'links' to see my completed projects.</h2></div></header><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/machine-learning/>Machine Learning</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/generalization-error-and-the-bias-variance-tradeoff/>Generalization Error and the Bias-Variance Tradeoff</a></h2><h3 class=article-subtitle>How bias and variance relate to underfitting/overfitting</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Feb 14, 2025</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>3 minute read</time></div></footer></div></header><section class=article-content><p>Remember, we want to avoid <strong>overfitting</strong> and <strong>underfitting</strong>. In overfitting, the model fits the noise in the training set and will not handle new data well. In underfitting, the model is not flexible enough to capture the relationship between variables and thus will also not be helpful in making predictions from new data.</p><p><img src=/p/generalization-error-and-the-bias-variance-tradeoff/overfitting_underfitting.png width=700 height=314 srcset="/p/generalization-error-and-the-bias-variance-tradeoff/overfitting_underfitting_hu_7470eadaa24340f1.png 480w, /p/generalization-error-and-the-bias-variance-tradeoff/overfitting_underfitting_hu_787ccddde4d5e020.png 1024w" loading=lazy alt="Source: DataCamp" class=gallery-image data-flex-grow=222 data-flex-basis=535px></p><p>A <strong>generalization error</strong> is a measure of how well a model generalizes to new data. It is based on bias, variance, and irreducible error. We want the lowest possible generalization error, finding a balance between bias and variance.</p><ul><li><strong>Bias</strong>: The errors a model makes due to its assumptions. Can lead to <strong>underfitting</strong> if the model fails to capture important patterns.<ul><li>Example: If a simple linear regression model is trained on complex non-linear data, it will likely have high bias.</li><li>To reduce bias: Use more complex models, add features, or improve feature engineering.</li></ul></li><li><strong>Variance</strong>: How sensitive the model is to fluctuations in the data. Can lead to <strong>overfitting</strong> if the model is trained to the noise rather than the underlying patterns.<ul><li>Example: A complex model with a lot of parameters fit to a small dataset may have high variance.</li><li>To reduce variance: Use regularization techniques, cross-validation, reduce model complexity, or gather more data.</li></ul></li><li><strong>Irreducible error</strong>: Noise. Errors that cannot be reduced due to choosing a &ldquo;better&rdquo; model.</li></ul><p>As bias increases, variance decreases, and vice versa. This is the bias-variance tradeoff.</p><p><img src=/p/generalization-error-and-the-bias-variance-tradeoff/bias_variance_tradeoff.png width=400 height=359 srcset="/p/generalization-error-and-the-bias-variance-tradeoff/bias_variance_tradeoff_hu_a24bd56542e13856.png 480w, /p/generalization-error-and-the-bias-variance-tradeoff/bias_variance_tradeoff_hu_78dda8cf3ceaf633.png 1024w" loading=lazy alt="Source: DataCamp" class=gallery-image data-flex-grow=111 data-flex-basis=267px></p><p>So, how do we practically deal with this? How do we estimate the generalization error?</p><p>We use cross-validation (K-Fold CV, Hold-Out CV) and compute the mean of the errors, then compare that to the training set errors.</p><ul><li>If CV error > training error: the model suffers from high variance (overfitting).</li><li>If CV error is similar to training error but greater than desired error: the model suffers from high bias (underfitting).</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Run the imports</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.tree</span> <span class=kn>import</span> <span class=n>DecisionTreeRegressor</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span><span class=p>,</span> <span class=n>cross_val_score</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>mean_squared_error</span> <span class=k>as</span> <span class=n>MSE</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Split the data</span>
</span></span><span class=line><span class=cl><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>test_size</span> <span class=o>=</span> <span class=mf>0.3</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>99</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Instantiate the decision tree regressor</span>
</span></span><span class=line><span class=cl><span class=n>dt</span> <span class=o>=</span> <span class=n>DecisionTreeRegressor</span><span class=p>(</span><span class=n>max_depth</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>min_samples_leaf</span><span class=o>=</span><span class=mf>0.14</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>99</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Evaluate the MSE/RMSE from 10-fold CV</span>
</span></span><span class=line><span class=cl><span class=n>MSE_CV</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>dt</span><span class=p>,</span> <span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;neg_mean_squared_error&#39;</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>RMSE_CV</span> <span class=o>=</span> <span class=p>(</span><span class=n>MSE_CV</span><span class=o>.</span><span class=n>mean</span><span class=p>())</span><span class=o>**</span><span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fit the model</span>
</span></span><span class=line><span class=cl><span class=n>dt</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create predictions from both train and test sets</span>
</span></span><span class=line><span class=cl><span class=n>y_predict_train</span> <span class=o>=</span> <span class=n>dt</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>y_predict_test</span> <span class=o>=</span> <span class=n>dt</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Evaluate the MSE/RMSE from training and test sets (Recall: RMSE is easier to interpet)</span>
</span></span><span class=line><span class=cl><span class=n>MSE_train</span> <span class=o>=</span> <span class=n>MSE</span><span class=p>(</span><span class=n>y_train</span><span class=p>,</span> <span class=n>y_predict_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>MSE_test</span> <span class=o>=</span> <span class=n>MSE</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_predict_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>RMSE_train</span> <span class=o>=</span> <span class=n>MSE_train</span> <span class=o>**</span> <span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>RMSE_test</span> <span class=o>=</span> <span class=n>MSE_test</span> <span class=o>**</span> <span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the MSE for the three outputs</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;CV MSE: </span><span class=si>{:.2f}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>MSE_CV</span><span class=o>.</span><span class=n>mean</span><span class=p>()))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Train MSE: </span><span class=si>{:.2f}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>MSE_train</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Test MSE: </span><span class=si>{:.2f}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>MSE_test</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Or, print the RMSE:</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;CV RMSE: </span><span class=si>{:.2f}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>RMSE_CV</span><span class=o>.</span><span class=n>mean</span><span class=p>()))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Train RMSE: </span><span class=si>{:.2f}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>RMSE_train</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Test RMSE: </span><span class=si>{:.2f}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>RMSE_test</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div></section><footer class=article-footer><section class=article-tags><a href=/tags/scikit-learn/>Scikit-Learn</a>
<a href=/tags/supervised-learning/>Supervised Learning</a>
<a href=/tags/python/>Python</a>
<a href=/tags/decision-trees/>Decision Trees</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>Last updated on Feb 14, 2025 00:00 UTC</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/p/decision-trees-for-regression/><div class=article-details><h2 class=article-title>Decision Trees for Regression</h2></div></a></article><article><a href=/p/decision-tree-learning/><div class=article-details><h2 class=article-title>Decision Tree Learning</h2></div></a></article><article><a href=/p/decision-tree-classification/><div class=article-details><h2 class=article-title>Decision Tree Classification</h2></div></a></article><article><a href=/p/ensemble-learning/><div class=article-details><h2 class=article-title>Ensemble Learning</h2></div></a></article><article><a href=/p/choosing-a-model/><div class=article-details><h2 class=article-title>Choosing a Model</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//hugo-theme-stack.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2025 Esther's Learning Journal</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>